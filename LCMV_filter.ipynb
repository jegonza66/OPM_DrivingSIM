{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a0d8de-9b94-49e5-8c0c-d84627f266ed",
   "metadata": {},
   "source": [
    "### The following code reads the forward and trans model and creates the reconstructed beamformer source activity using LCMV filters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b184306-8ee8-40a1-90cf-f7d2d2f918a9",
   "metadata": {},
   "source": [
    "need epoch data; the following script is not complete and assumes that the epoch/ evoked data is already loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f01ce-e31e-4d32-a3fb-8615e8cbca45",
   "metadata": {},
   "source": [
    "# # Read forward model and trans file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157838b0-9f08-4898-80d6-1744cd451b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.beamformer import apply_lcmv, make_lcmv\n",
    "from mne import read_source_estimate\n",
    "\n",
    "subject = subject\n",
    "\n",
    "base_dir = (r'C:\\Users\\lpxaj7\\OneDrive - The University of Nottingham\\Documents\\Experiments\\Year_1\\v0_1')\n",
    "fs_path = os.path.join(base_dir,'DA\\\\all_files', subject, '')\n",
    "\n",
    "\n",
    "\n",
    "fwd_fname = str(fs_path + f'{subject}-fwd.fif')\n",
    "forward = mne.read_forward_solution(fwd_fname)\n",
    "forward['info']\n",
    "\n",
    "\n",
    "#trans file\n",
    "\n",
    "import numpy as np\n",
    "from mne.transforms import apply_trans, Transform\n",
    "\n",
    "trans_file=(fs_path + f'{subject}-trans.fif')  #'15463_2-trans.fif'\n",
    "\n",
    "if subject =='15463':\n",
    "    trans_file=(fs_path + f'{subject}_2-trans.fif')  #'15463\n",
    "    \n",
    "# Get the transformation matrix\n",
    "mri_trans = mne.read_trans(trans_file)  # Transformation matrix\n",
    "\n",
    "subjects_dir=fs_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e3f7f6-88e4-4099-b3e1-5b1690315858",
   "metadata": {},
   "source": [
    "# Define Epochs for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaba5a3c-2da2-4bc6-a55a-5e8e3d41e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%%% define values of epocch/ evoked and mni cords to plot\n",
    "##%% epoch visuLalization\n",
    "right_ep= epochs_new[\"rightVF\"] # right vf implies left hemisphere brain areas to look for \n",
    "left_ep = epochs_new[\"leftVF\"]\n",
    "\n",
    "#left epoch\n",
    "epoch_visualise = left_ep\n",
    "\n",
    "evoked = epoch_visualise.average()\n",
    "evoked.plot()\n",
    "\n",
    "\n",
    "#mni cord to plot (mm)\n",
    "# cord=[36, -28, 37]  # right sensorimotor in mm\n",
    "\n",
    "#right_epochs\n",
    "\n",
    "# epoch_visualise = right_ep\n",
    "# #mni cord to plot (mm)\n",
    "# cord=[-36,-14,56]  # left sensorimotor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02cc8d-c23c-4453-8847-c0b2582d8c45",
   "metadata": {},
   "source": [
    "# compute active and data cov matrix\n",
    "active window is window of interest and control is baseline/rest period for the epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f438bb-ea49-4e90-9ab8-dae06b2ded7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%%%%%%%%%%%%%%%%%% sourcespace\n",
    "active_data_cov=  mne.compute_covariance(epoch_visualise, method='empirical', tmin=0.02, tmax=0.2)\n",
    "control_data_cov=  mne.compute_covariance(epoch_visualise, method='empirical', tmin=0.6, tmax=0.78)\n",
    "data_cov=active_data_cov+control_data_cov\n",
    "figs= data_cov.plot(epoch_visualise.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc7041a-091e-4bf2-b5ab-1cd8134611ee",
   "metadata": {},
   "source": [
    "#### if the channels in forward model and data cov is not equal to channels in info object\n",
    "#### then it causes a problem, therefore if needed restrict the forward solution to picked/ selected channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59486bfe-34a0-40fe-9ea9-92bbb70391c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict forward solution to the picked/selected channels\n",
    "forward_pick = forward.copy().pick_channels(ch_names=evoked.info['ch_names'])\n",
    "\n",
    "# Restrict data covariance to the picked channels\n",
    "data_cov_pick = data_cov.copy().pick_channels(ch_names=evoked.info['ch_names'])\n",
    "\n",
    "# save a bit of memory\n",
    "src = forward_pick[\"src\"]\n",
    "# del forward_pick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952a96c0-b2ae-4526-9cde-47abf292bed3",
   "metadata": {},
   "source": [
    "# make LCMV filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859575e-1c14-425a-86a4-28d45774153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# right_ep.load_data()  # This loads the data into memory\n",
    "# evoked_left_beta=right_ep.copy().filter(13,30).average()\n",
    "\n",
    "filters = make_lcmv(\n",
    "    evoked.info,\n",
    "    forward_pick,\n",
    "    data_cov_pick,\n",
    "    reg=0.05,\n",
    "    pick_ori=\"max-power\",\n",
    "    weight_norm=\"unit-noise-gain\",\n",
    "    rank=None,\n",
    ")\n",
    "\n",
    "# vector filters  # if needed\n",
    "filters_vec = make_lcmv(\n",
    "    evoked.info,\n",
    "    forward_pick,\n",
    "    data_cov_pick,\n",
    "    reg=0.05,\n",
    "    pick_ori=\"vector\",\n",
    "    weight_norm=\"unit-noise-gain-invariant\", #unit-noise-gain \n",
    "    rank=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3eafca-1db4-4319-b3c2-e18bd93d672b",
   "metadata": {},
   "source": [
    "# compute pseudo t-stats\n",
    "\n",
    "Calculate the changed in relative power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23f070-8d4a-4440-87b4-325ef68b019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute pseudoi t stats\n",
    "stc_active=mne.beamformer.apply_lcmv_cov(active_data_cov, filters)\n",
    "stc_control=mne.beamformer.apply_lcmv_cov(control_data_cov, filters)\n",
    "stc= (stc_active-stc_control)/stc_control   ## when calculating stc active-control /pseudoo tstqats, we get only one time point value so no pattern in 2nd panel\n",
    "##compares power between active and control periods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63483b3f-df9e-46ae-948d-8d5d504713bb",
   "metadata": {},
   "source": [
    "# visualise reconstructed source activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe645cb-c4bd-4135-b825-a8ca6a7286e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lims=[0.3, 0.45, 0.6]\n",
    "\n",
    "kwargs= dict(\n",
    "    src=src,\n",
    "    subject=subject,\n",
    "    subjects_dir=fs_path,\n",
    "   # initial_pos=mri_voxel_coords,   # initial_pos=(36, -28, 37),\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "# visualise reconstructed activity\n",
    "#ON MRI slices\n",
    "brain=stc.plot(**kwargs)  ## when calculating stc active-control /pseudoo tstqats, we get only one time point value so no pattern in 2nd panel\n",
    "\n",
    "#on glass brain\n",
    "brain=stc.plot(mode=\"glass_brain\",**kwargs)  ## when calculating stc active-control /pseudoo tstqats, we get only one time point value so no pattern in 2nd panel\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
