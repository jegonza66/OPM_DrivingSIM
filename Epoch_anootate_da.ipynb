{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab80e688-5c92-4f65-8928-586a487f36e8",
   "metadata": {},
   "source": [
    "## CREATE EPOCHS AND LABEL DATA BASED ON DA SYMBOL STIMULI\n",
    "The following file create annotations based on divided attention(DA) timepoints as they appear in the video.\n",
    "this enables the epochs data to be seperated into right and left visual field \n",
    "epochs are then created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecce854-1bfd-4a6e-b191-505179a6404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "import pathlib\n",
    "import re\n",
    "import os\n",
    "import mne\n",
    "from mne.datasets.eyelink import data_path\n",
    "from mne.preprocessing.eyetracking import read_eyelink_calibration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from mne.time_frequency import tfr_morlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c087ac86-3eec-4c96-81fd-42471ee7263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject='11766'# '15463'#\n",
    "subj='1'  #'8'#\n",
    "task='DA'  #'HD'\n",
    "\n",
    "path1=r'C:\\Users\\lpxaj7\\OneDrive - The University of Nottingham\\Documents\\Experiments\\Year_1\\v0_1\\\\'\n",
    "path1= os.path.join(path1,task)\n",
    "\n",
    "savefigpath= os.path.join(path1,'analysis',subject,'button_source','')\n",
    "os.makedirs(savefigpath, exist_ok=True)\n",
    "\n",
    "\n",
    "#MEG\n",
    "filename_meg=str(subj+'_'+task+'_3_raw_ica_hfc_meg.fif')\n",
    "if subject=='15463':\n",
    "    filename_meg=str(subj+'_'+'raw_ica_hfc_meg.fif')\n",
    "\n",
    "read_file_meg=os.path.join(path1,'all_files',subject,filename_meg)\n",
    "\n",
    "# #ET\n",
    "savefigpath1=r'C:\\Users\\lpxaj7\\OneDrive - The University of Nottingham\\Documents\\codes\\eyetracker\\\\'\n",
    "fig_path_source= os.path.join(path1,'analysis','sourcespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454df827-65cd-4517-a1a0-23e0630422ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant=subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fa656-3c35-4a26-acaa-ab0b454eb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% load data\n",
    "\n",
    "#MEG\n",
    "raw_meg=mne.io.read_raw_fif(read_file_meg,preload=True)\n",
    "print(raw_meg.info)\n",
    "\n",
    "# also check what time is mentioned as first time of the samples\n",
    "raw_meg.copy()._first_time # that is the origin or starting time\n",
    "\n",
    "original_raw_meg=raw_meg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458283a-d42c-4fee-ba3c-31d94f487b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% visualise raw data\n",
    "mag_channels= mne.pick_types(raw_meg.info,meg='mag')\n",
    "scalings = {'mag':1e-11,'stim':3}\n",
    "\n",
    "\n",
    "#raw_meg.drop_channels(['et_x'])\n",
    "  # plot all channels together with a duration of 60 secs\n",
    "raw_meg.plot(title='RAW DATA', n_channels=len(mag_channels),duration=60)\n",
    "\n",
    "##%% channels marked as bad check\n",
    "print(raw_meg.info[\"bads\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7956a485-e681-4321-9d3c-e246235b5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% broadband filter and psd\n",
    "fmin=1\n",
    "fmax=99\n",
    "# tmin= \n",
    "raw_bb= raw_meg.filter(fmin,fmax)\n",
    "raw_bb.plot_psd(fmin=0, fmax=fmax+10,  exclude='bads')#,title=f' PSD {subject} {fmin}_{fmax}')\n",
    "plt.show()\n",
    "##%% apply hfc\n",
    "raw= raw_bb.copy()\n",
    "# raw_bb2= raw_bb.copy()\n",
    "\n",
    "bad_ch=['T1','T2','T3','T4','T5','T6','T7','T8','T9','T10','T11',\\\n",
    "        'A1','A3','A5','A7','A8','A10','A12','A14','A16']\n",
    "raw_bb.info['bads'].extend(bad_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5410540-a230-4382-a18d-1b918b6d0672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read files\n",
    "##%%et\n",
    "#ET\n",
    "\n",
    "filename_et= (subj+'_'+task+'.asc')\n",
    "read_file_et=os.path.join(path1,os.pardir,os.pardir,'v0\\\\DrivingSim\\\\ET\\\\ET_allfiles',filename_et)\n",
    "\n",
    "raw_et = mne.io.read_raw_eyelink(read_file_et)#, preload=True)#,create_annotations=[\"blinks\"])\n",
    "\n",
    "raw_et.info\n",
    "##%%\n",
    "#raw_events=raw_bb.copy()\n",
    "##%% da_time\n",
    "\n",
    "#Divided attention timepoints file \n",
    "da_time_file= savefigpath1 + f'da_time_{subj}.csv'   # all data of da symbols appear from eyetracker video\n",
    "da_time= pd.read_csv(da_time_file,header=None,names=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46f5a5-dfa7-45a3-b0c3-39f2c0473171",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% selecting events\n",
    "# select events based on button press only for DA task ehich is between 200 to 700ms\n",
    "raw_file=raw_beta.copy()\n",
    "\n",
    "#raw_file=raw.copy()\n",
    "#del raw\n",
    "events= mne.find_events(raw_file.copy().crop(tmin=200, tmax=700), stim_channel=\"button press\")\n",
    "raw_file.copy().plot(events=events)\n",
    "\n",
    "\n",
    "# for epoch data just filter da events for this analysis\n",
    "\n",
    "raw_file_epochs= raw_file.copy().crop(tmin=200, tmax=700).pick_types(meg=True, stim=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##%%\n",
    "#raw_file.annotations.rename({'saccade':'BAD_saccade'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a2ec6-7f3b-4302-a3ab-9ad2a7eb2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% labelling events based on DA symbol appeareance (32)\n",
    "\n",
    "old_annot= raw_file.annotations.onset - raw_file._first_time # (subtracting this to accomodate for first sample automatic correction  by mne)\n",
    "old_annot_descp= raw_file.annotations.description\n",
    "old_annot_duration= raw_file.annotations.duration\n",
    "\n",
    "# the screen recording of et started from this point w and we have obtained symbol values from this recording therefore need to add this value to all symbol appearance data\n",
    "drive_strart = raw_et.annotations[raw_et.annotations.description == '-6 Record Screen Started: screenrecording.mp4']\n",
    "dri_start_time= drive_strart.onset  #raw_et._first_time=0\n",
    "\n",
    "#conver df to 1d numpy array\n",
    "# onset_da=da_time.values.flatten()+drive_strart.onset# +raw_file._first_time  # raw_file.annotations.onset[-1]\n",
    "onset_da=da_time+drive_strart.onset# +raw_file._first_time  # raw_file.annotations.onset[-1]\n",
    "\n",
    " # FIRST LETTER REPRESENt symbol direction, 2nd represent visual field in which presented\n",
    "decp=['LR', 'LL', 'UL', 'LL',\\\n",
    "'DL', 'LR', 'RR', 'UR',\\\n",
    "'RR', 'UL', 'DR', 'RL',\\\n",
    "'LR', 'DR', 'DL', 'RR',\\\n",
    "'UR', 'LL', 'LR', 'DL',\\\n",
    "'RL', 'RL', 'UR', 'DR',\\\n",
    "'RL', 'DR', 'UL', 'RR',\\\n",
    "'LL', 'UL', 'DL', 'UR']\n",
    "description_da= decp   #['DA']*len(onset_da)\n",
    "dur_da= [4.5]*len(onset_da)\n",
    "\n",
    "onset=[]; description=[];duration=[]\n",
    "onset= np.append(old_annot, onset_da)\n",
    "#onset= onset * (500 / 375)\n",
    "\n",
    "description= np.append(old_annot_descp,description_da)\n",
    "\n",
    "duration=np.append(old_annot_duration,dur_da)#[0]*len(onset)\n",
    "\n",
    "annotations = mne.Annotations(onset, duration=duration, description=description)#, orig_time=raw_events._first_time)\n",
    "#raw_file.set_annotations(annotations)\n",
    "\n",
    "# Add annotations to raw data\n",
    "raw_events=raw_file.copy()\n",
    "\n",
    "raw_events.set_annotations(annotations)\n",
    "raw_events.plot()\n",
    "#raw_events.copy().pick_channels([\"button press\"]).plot(events=events,picks='stim')\n",
    "#del raw_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c876962-d5cc-427c-b7d2-6d9fb1220555",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%% relabel events based on annotations\n",
    "annot_dict= {0: ['UL', 'LR', 'RL', 'DR'], \n",
    " 1: ['DL', 'LL'], \n",
    " 4: ['RR', 'UR']}\n",
    "\n",
    "labelled_event=[]\n",
    "for event in events:\n",
    "    # Get the time of the event in seconds\n",
    "    event_time = round((event[0] / raw_file.info['sfreq']-raw_file._first_time),2)  # remove first sample time\n",
    "    event= np. insert(event, 3, event_time)\n",
    "\n",
    "    print(event_time)\n",
    "     # Find the most recent annotation before the event  \n",
    "    for ann in annotations:\n",
    "        if (ann['description'] in decp and (ann['onset']<= event_time) & (ann['onset']+10 >= (event_time))):  # 10 is added just to ensurethat button might have been pressed even after 5 seconds of symbol disaapearence (symbol diaapears after 4.5 sec: 4.5+5 )\n",
    "            print(ann)    \n",
    "            prev_annotations= ann            \n",
    "            descp= int([key for key, value in annot_dict.items() if prev_annotations['description'] in value][0])\n",
    "            diff= event_time-ann['onset'] # tells difference between button press and symbol time\n",
    "            print('ons= ',ann['onset'] ) \n",
    "            \n",
    "            \n",
    "     \n",
    "    # prev_annotations = [ann for ann in annotations if ann['onset'] < event_time]\n",
    "    # #print(prev_annotations)\n",
    "    # Get the label of the most recent annotation if there is any\n",
    "    if prev_annotations:\n",
    "        event[2]= descp\n",
    "        event= np.insert(event,4, diff)\n",
    "        #event=np.insert(event,5, onsett)\n",
    "    else: \n",
    "        continue\n",
    "    # Append the event and its label to the labeled events list\n",
    "    labelled_event.append(event)\n",
    "\n",
    "# convert the list to an array\n",
    "event_list=np.array([row[:3] for row in labelled_event])  # keep only first 3 columns tthat contain event details\n",
    "\n",
    "#added line on 4/11/24\n",
    "raw_file_epochs= raw_file.copy().crop(tmin=200, tmax=700).pick_types(meg=True, stim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb6053-caba-41b5-948b-04e2311773c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##%%% create epochs\n",
    "event_dict= {\n",
    "    'leftVF':1,\n",
    "    'rightVF':4\n",
    "    #'incorrect':0\n",
    "    }\n",
    "\n",
    "##%%%%%%%\n",
    "\n",
    "\n",
    "epochs_new= mne.Epochs(\n",
    "    raw_file_epochs, \n",
    "    event_list, \n",
    "    tmin= -2, \n",
    "    tmax=2, \n",
    "    event_id= event_dict, \n",
    "    reject_by_annotation=False, \n",
    "    picks=['meg'],\n",
    "    baseline=None\n",
    " )\n",
    "\n",
    "epochs_new.plot(n_epochs=10, events=True)\n",
    "##%% removing bad epochs thru sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d8842-c390-4776-8709-563737443e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean epochs; \n",
    "epoch_data= epochs_new.get_data()   #array of shape (n_epochs, n_channels, n_times)\n",
    "epochs_sd= epoch_data.std(axis=2)    # Standard deviation across time within each epoch for each channel\n",
    "  #average standard deviation of the signal at that sensor across all trials\n",
    "\n",
    "time_sd= epoch_data.std(axis=0)   # Standard deviation across epochs  for each channel x time\n",
    "mean_time_sd= time_sd.mean(axis=1)  # mean of above\n",
    "\n",
    "# Get the channel names from the info\n",
    "channel_names = np.array(epochs_new.ch_names)\n",
    "\n",
    "# Dictionary to store bad channels for each epoch\n",
    "bad_channels_per_epoch = {}\n",
    "bad_trials=[]\n",
    "\n",
    "\n",
    "for i, epoch_sd in enumerate(epochs_sd):    # for each epoch, channel\n",
    "    # Boolean array where True indicates a channel's sd exceeds the threshold \n",
    "    bad_channels_mask = (epoch_sd > 3*mean_time_sd)|  (epoch_sd <- 3*mean_time_sd)     #or epoch_sd < mean_sd - 3 * std_sd  #mean_sd mean_sd+ 2\n",
    "    #print(bad_channels_mask)\n",
    "    if np.any(bad_channels_mask):\n",
    "        bad_trials.append(i)\n",
    "    # Get the names of the bad channels\n",
    "    bad_channels = channel_names[bad_channels_mask]\n",
    "    \n",
    "    bad_channels_per_epoch[i] = bad_channels.tolist()\n",
    "\n",
    "# # Drop bad trials\n",
    "epochs_new.drop(bad_trials, reason='HIGH_STD')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
